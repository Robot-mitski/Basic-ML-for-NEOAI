{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["eb71b2d7","3dbeab72","98934cf6"],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"64d60d94","cell_type":"markdown","source":"### Task: Sentiment Classification of Movie Reviews  \n","metadata":{"id":"64d60d94"}},{"id":"MnFtJo_vQ7fd","cell_type":"markdown","source":"Alice is a time traveler who visits different eras in the past to solve important missions. While there, she must always be careful to disguise herself so that no one will know she is from the future. This time, she joined an NLP company in 2014 year and was assigned the task of sentiment analysis on user reviews for movies. Help Alice with this task.","metadata":{"id":"MnFtJo_vQ7fd"}},{"id":"09CmnLTit1a0","cell_type":"markdown","source":"You need to solve sentiment classification task using the imdb movie review dataset. Each review is labeled as either positive (1) or negative (0), indicating its sentiment. You will be provided by basic LinearSVC classifier with TF-IDF features.\n\nYou need to solve 3 tasks:\n\n1.   Task1: Text Preprocessing with spaCy (this is your baseline)\n2.   Task 2: Adding Part-of-Speech (POS) Features as a TF-IDF for Each POS Category\n3.   Task 3: Development of new features to improve classification accuracy\n\n**Note!** Do not change the classifier. Change only cells with TODO mark.\n\n","metadata":{"id":"09CmnLTit1a0"}},{"id":"995ac04c","cell_type":"code","source":"import os\nimport random\nimport re\nimport numpy as np\nimport pandas as pd\nimport spacy\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_extraction.text import (\n    TfidfVectorizer,\n    CountVectorizer,\n)\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"id":"995ac04c","outputId":"b88f7860-9118-44ea-9e9a-535361352a54","colab":{"base_uri":"https://localhost:8080/","height":372},"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:49:45.602250Z","iopub.execute_input":"2025-03-20T14:49:45.602492Z","iopub.status.idle":"2025-03-20T14:49:54.847773Z","shell.execute_reply.started":"2025-03-20T14:49:45.602453Z","shell.execute_reply":"2025-03-20T14:49:54.846856Z"}},"outputs":[],"execution_count":1},{"id":"e83541ef","cell_type":"code","source":"os.environ[\"PYTHONHASHSEED\"] = str(42)\n\nrandom.seed(42)\nnp.random.seed(42)","metadata":{"id":"e83541ef","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:50:02.984323Z","iopub.execute_input":"2025-03-20T14:50:02.984607Z","iopub.status.idle":"2025-03-20T14:50:02.988495Z","shell.execute_reply.started":"2025-03-20T14:50:02.984582Z","shell.execute_reply":"2025-03-20T14:50:02.987816Z"}},"outputs":[],"execution_count":2},{"id":"e40afc00","cell_type":"markdown","source":"### Loading the dataset","metadata":{"id":"e40afc00"}},{"id":"4e_6CBdQXOD1","cell_type":"code","source":"! gdown --id 1C6TIP8c33fHM6dxs6DoxJeKY6ZXGWpBx\n! gdown --id 1K8WBFVVvVlsvIMRG8HiaFkldiyuNkLD2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4e_6CBdQXOD1","outputId":"9c083343-3f94-4cce-d074-b582e53d3e36","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:50:05.331656Z","iopub.execute_input":"2025-03-20T14:50:05.332016Z","iopub.status.idle":"2025-03-20T14:50:17.919733Z","shell.execute_reply.started":"2025-03-20T14:50:05.331989Z","shell.execute_reply":"2025-03-20T14:50:17.918763Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1C6TIP8c33fHM6dxs6DoxJeKY6ZXGWpBx\nTo: /kaggle/working/imdb_train_hw1.csv\n100%|██████████████████████████████████████| 8.25M/8.25M [00:00<00:00, 40.9MB/s]\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1K8WBFVVvVlsvIMRG8HiaFkldiyuNkLD2\nTo: /kaggle/working/imdb_test_hw1.csv\n100%|███████████████████████████████████████| 2.10M/2.10M [00:00<00:00, 157MB/s]\n","output_type":"stream"}],"execution_count":3},{"id":"808c6df4","cell_type":"code","source":"df_train = pd.read_csv(\"imdb_train_hw1.csv\")\ndf_test = pd.read_csv(\"imdb_test_hw1.csv\")\ndf_train.sample(5)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"808c6df4","outputId":"70b1bec8-b442-4ba3-aaf6-628199bee0ad","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:50:25.331159Z","iopub.execute_input":"2025-03-20T14:50:25.331491Z","iopub.status.idle":"2025-03-20T14:50:25.485369Z","shell.execute_reply.started":"2025-03-20T14:50:25.331459Z","shell.execute_reply":"2025-03-20T14:50:25.484627Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0  label                                               text\n8681        8681      1  I noticed this movie was getting trashed well ...\n2362        2362      1  When it comes to creating a universe George Lu...\n6232        6232      0  \"National Treasure\" (2004) is a thoroughly mis...\n1318        1318      1  I must admit - the only reason I bought this m...\n543          543      1  Ten out of the 11 short films in this movie ar...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8681</th>\n      <td>8681</td>\n      <td>1</td>\n      <td>I noticed this movie was getting trashed well ...</td>\n    </tr>\n    <tr>\n      <th>2362</th>\n      <td>2362</td>\n      <td>1</td>\n      <td>When it comes to creating a universe George Lu...</td>\n    </tr>\n    <tr>\n      <th>6232</th>\n      <td>6232</td>\n      <td>0</td>\n      <td>\"National Treasure\" (2004) is a thoroughly mis...</td>\n    </tr>\n    <tr>\n      <th>1318</th>\n      <td>1318</td>\n      <td>1</td>\n      <td>I must admit - the only reason I bought this m...</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>543</td>\n      <td>1</td>\n      <td>Ten out of the 11 short films in this movie ar...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"MkhanC2f0J5t","cell_type":"code","source":"y_train = df_train[\"label\"]\ny_test = df_test[\"label\"]","metadata":{"id":"MkhanC2f0J5t","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:50:42.860314Z","iopub.execute_input":"2025-03-20T14:50:42.860600Z","iopub.status.idle":"2025-03-20T14:50:42.864591Z","shell.execute_reply.started":"2025-03-20T14:50:42.860577Z","shell.execute_reply":"2025-03-20T14:50:42.863630Z"}},"outputs":[],"execution_count":5},{"id":"fe84f9a2","cell_type":"markdown","source":"Since the classes in our dataset are nearly balanced, we can use accuracy as the evaluation metric. Accuracy provides a straightforward measure of how well the model classifies reviews correctly across both sentiment classes.  \n\nHowever, we will consider the F1-score for a more detailed performance assessment. Even with balanced classes, the model might still be biased towards one class due to feature distributions (e.g., it may predict negative reviews more confidently than positive ones).  \n\nThe F1-score, which is the harmonic mean of precision and recall, helps us identify such imbalances. It ensures that both false positives and false negatives are accounted for, providing a better understanding of how well the model performs on each sentiment class.","metadata":{"id":"fe84f9a2"}},{"id":"8cb026b8","cell_type":"markdown","source":"## 0. LinearSVC with TF-IDF Features  \n\nWe will now train a LinearSVC model using TF-IDF (Term Frequency-Inverse Document Frequency) as features.","metadata":{"id":"8cb026b8"}},{"id":"ad2e6298","cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(df_train[\"text\"])\nX_test_tfidf = vectorizer.transform(df_test[\"text\"])","metadata":{"id":"ad2e6298","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:51:11.383305Z","iopub.execute_input":"2025-03-20T14:51:11.383608Z","iopub.status.idle":"2025-03-20T14:51:12.718349Z","shell.execute_reply.started":"2025-03-20T14:51:11.383583Z","shell.execute_reply":"2025-03-20T14:51:12.717682Z"}},"outputs":[],"execution_count":6},{"id":"9967a971","cell_type":"code","source":"y_train = df_train[\"label\"]\ny_test = df_test[\"label\"]","metadata":{"id":"9967a971","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:51:17.341577Z","iopub.execute_input":"2025-03-20T14:51:17.341908Z","iopub.status.idle":"2025-03-20T14:51:17.345518Z","shell.execute_reply.started":"2025-03-20T14:51:17.341880Z","shell.execute_reply":"2025-03-20T14:51:17.344749Z"}},"outputs":[],"execution_count":7},{"id":"fcdbbec5","cell_type":"code","source":"model = LinearSVC(random_state=42)\nmodel.fit(X_train_tfidf, y_train)\ny_pred = model.predict(X_test_tfidf)\nprint(\"Accuracy (TF-IDF):\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcdbbec5","outputId":"71343aa4-7b84-418a-c9c0-2c31da49d71c","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:51:20.091987Z","iopub.execute_input":"2025-03-20T14:51:20.092359Z","iopub.status.idle":"2025-03-20T14:51:20.229370Z","shell.execute_reply.started":"2025-03-20T14:51:20.092319Z","shell.execute_reply":"2025-03-20T14:51:20.228325Z"}},"outputs":[{"name":"stdout","text":"Accuracy (TF-IDF): 0.841747984726347\n              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85      1213\n           1       0.83      0.84      0.84      1144\n\n    accuracy                           0.84      2357\n   macro avg       0.84      0.84      0.84      2357\nweighted avg       0.84      0.84      0.84      2357\n\n","output_type":"stream"}],"execution_count":8},{"id":"411df717","cell_type":"markdown","source":"The model's accuracy using TF-IDF is 0.8417 (84.17%) this our **baseline result**.","metadata":{"id":"411df717"}},{"id":"1028a21b","cell_type":"markdown","source":"## Task1: Text Preprocessing with spaCy\n\nLemmatize original review texts with [spacy ](https://spacy.io/usage/linguistic-features#lemmatization)library.\nWith spacy remove:\n\n*   stop words\n*   punctuation\n*   digits\n*   emails\n*   numbers\n*   empty word\n\nTrain classifier with a new tf-idf representation of text. Obtain baseline classification metrics.","metadata":{"id":"1028a21b"}},{"id":"e2309901-3d5f-4135-95de-9613d2ab6b0d","cell_type":"code","source":"import pandas as pd\nimport string\n\n# Функция для очистки текста\ndef clean_text(text):\n    # Приводим текст к нижнему регистру\n    text = text.lower()\n    # Удаляем знаки препинания\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # Убираем пробелы\n    text = text.replace(\" \", \"\")\n    return text\n\n# Загрузка данных\ndf_train = pd.read_csv(\"imdb_train_hw1.csv\")\n\n# Применение функции clean_text к текстам\ndf_train[\"text_cleaned\"] = df_train[\"text\"].apply(clean_text)\n\n# Вывод первых 5 строк для проверки\nprint(df_train[[\"text\", \"text_cleaned\"]].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:41:55.425358Z","iopub.execute_input":"2025-03-20T15:41:55.425707Z","iopub.status.idle":"2025-03-20T15:41:55.697390Z","shell.execute_reply.started":"2025-03-20T15:41:55.425683Z","shell.execute_reply":"2025-03-20T15:41:55.696686Z"}},"outputs":[{"name":"stdout","text":"                                                text  \\\n0  So, this movie has been hailed, glorified, and...   \n1  This Filmfour funded Sci-Fi movie is most defi...   \n2  Okay this is stupid,they say their not making ...   \n3  Of course, by any normal standard of film crit...   \n4  What the movie The 60s really represents (to t...   \n\n                                        text_cleaned  \n0  sothismoviehasbeenhailedglorifiedandcarriedtoi...  \n1  thisfilmfourfundedscifimovieismostdefinitelyam...  \n2  okaythisisstupidtheysaytheirnotmakinganotherni...  \n3  ofcoursebyanynormalstandardoffilmcriticismsold...  \n4  whatthemoviethe60sreallyrepresentstothoseofusw...  \n","output_type":"stream"}],"execution_count":34},{"id":"bc0fe2f6","cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\n# TODO: function to clean text using spaCy\ndef clean_text(text):\n    doc = nlp(text)\n    cleaned_tokens = []\n    for token in doc:\n        if not token.is_stop and not token.is_punct and not token.is_digit and not token.like_email and not token.like_num and not token.is_space:\n            cleaned_tokens.append(token.lemma_)\n    return \" \".join(cleaned_tokens)","metadata":{"id":"bc0fe2f6","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:41:58.839285Z","iopub.execute_input":"2025-03-20T15:41:58.839571Z","iopub.status.idle":"2025-03-20T15:41:59.450176Z","shell.execute_reply.started":"2025-03-20T15:41:58.839548Z","shell.execute_reply":"2025-03-20T15:41:59.449515Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"}],"execution_count":35},{"id":"8bb510b1","cell_type":"code","source":"df_train[\"text_lemmatized\"] = df_train[\"text\"].apply(clean_text)\ndf_test[\"text_lemmatized\"] = df_test[\"text\"].apply(clean_text)","metadata":{"id":"8bb510b1","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:42:08.573031Z","iopub.execute_input":"2025-03-20T15:42:08.573323Z","iopub.status.idle":"2025-03-20T15:46:48.097291Z","shell.execute_reply.started":"2025-03-20T15:42:08.573300Z","shell.execute_reply":"2025-03-20T15:46:48.096583Z"}},"outputs":[],"execution_count":36},{"id":"c29cf065","cell_type":"code","source":"# TODO get tf-idf vectors for your lemmatized texts\n\nvectorizer = TfidfVectorizer()\nX_train_tfidf_lemmatized = vectorizer.fit_transform(df_train[\"text_lemmatized\"])\nX_test_tfidf_lemmatized = vectorizer.transform(df_test[\"text_lemmatized\"])","metadata":{"id":"c29cf065","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:46:48.781667Z","iopub.execute_input":"2025-03-20T15:46:48.781969Z","iopub.status.idle":"2025-03-20T15:46:49.455976Z","shell.execute_reply.started":"2025-03-20T15:46:48.781948Z","shell.execute_reply":"2025-03-20T15:46:49.455279Z"}},"outputs":[],"execution_count":38},{"id":"e1a5e75a","cell_type":"code","source":"model = LinearSVC(random_state=42)\nmodel.fit(X_train_tfidf_lemmatized, y_train)\ny_pred = model.predict(X_test_tfidf_lemmatized)\nprint(\"Accuracy (TF-IDF):\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"id":"e1a5e75a","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:46:49.456841Z","iopub.execute_input":"2025-03-20T15:46:49.457055Z","iopub.status.idle":"2025-03-20T15:46:49.544064Z","shell.execute_reply.started":"2025-03-20T15:46:49.457037Z","shell.execute_reply":"2025-03-20T15:46:49.543256Z"}},"outputs":[{"name":"stdout","text":"Accuracy (TF-IDF): 0.8413237165888842\n              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.84      1213\n           1       0.83      0.85      0.84      1144\n\n    accuracy                           0.84      2357\n   macro avg       0.84      0.84      0.84      2357\nweighted avg       0.84      0.84      0.84      2357\n\n","output_type":"stream"}],"execution_count":39},{"id":"5itZ2DUtzUJ5","cell_type":"markdown","source":"This is your **baseline** metrics!","metadata":{"id":"5itZ2DUtzUJ5"}},{"id":"72baffa9","cell_type":"markdown","source":"## Task 2: Adding Part-of-Speech (POS) Features as a TF-IDF for Each POS Category\n\nFor each text add part-of-speach (pos) tags as feature in TF-IDF manner. Use Spacy to get pos tag features. Combine them with lemmatized tf-idf features, obtained in the Task1.\n\nFor example, if you have two sentences with following tf-idf vectors:\n\n1.   sent1: \"The cat sat on the mat.\" -> [0.63, 0.44, 0.31, 0.31, 0.44, 0, 0]\n2.   sent2: \"The dog sat on the floor. \" -> [0.63, 0, 0.31, 0.31, 0, 0.44, 0.44]\n\nAnd you obtained the following pos tag features (with dictionary {'det': 1, 'noun': 2, 'verb': 3, 'adp': 0}):\n\n*   sent1: [0.63, 0.63, 0.31, 0.31]\n*   sent2: [0.63, 0.63, 0.31, 0.31]\n\n\nThen final representation should be:\n\n*   sent1: [0.63, 0.44, 0.31, 0.31, 0.44, 0, 0, 0.63, 0.63, 0.31, 0.31]\n*   sent2: [0.63, 0, 0.31, 0.31, 0, 0.44, 0.44, 0.63, 0.63, 0.31, 0.31]\n\n**Note!** Do not use pos tags punctuation and empty words","metadata":{"id":"72baffa9"}},{"id":"674b790b","cell_type":"markdown","source":"We need to bring the features obtained by CountVectorizer for POS tags to the same scale as TF-IDF. The easiest way is to apply TfidfTransformer to the CountVectorizer result.","metadata":{"id":"674b790b"}},{"id":"8189f9cc-fd83-47b3-9e60-671f3b83ae25","cell_type":"code","source":"import pandas as pd\nimport spacy\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.sparse import hstack\n\ndf_train = pd.read_csv(\"imdb_train_hw1.csv\")\ndf_test = pd.read_csv(\"imdb_test_hw1.csv\")\n\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n\ndef clean_text(text):\n    doc = nlp(text)\n    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n    return \" \".join(cleaned_tokens)\n\ndf_train[\"text_lemmatized\"] = df_train[\"text\"].apply(clean_text)\ndf_test[\"text_lemmatized\"] = df_test[\"text\"].apply(clean_text)\n\ntfidf_vectorizer = TfidfVectorizer()\nX_train_tfidf_lemmatized = tfidf_vectorizer.fit_transform(df_train[\"text_lemmatized\"])\nX_test_tfidf_lemmatized = tfidf_vectorizer.transform(df_test[\"text_lemmatized\"])\n\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n\ndef extract_pos_tags(text):\n    doc = nlp(text)\n    pos_tags = [token.pos_ for token in doc if token.pos_ in {\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"}]\n    return \" \".join(pos_tags)\n\ndf_train[\"pos_text\"] = df_train[\"text\"].apply(extract_pos_tags)\ndf_test[\"pos_text\"] = df_test[\"text\"].apply(extract_pos_tags)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:40:31.669401Z","iopub.execute_input":"2025-03-20T16:40:31.669700Z","iopub.status.idle":"2025-03-20T16:44:55.536810Z","shell.execute_reply.started":"2025-03-20T16:40:31.669677Z","shell.execute_reply":"2025-03-20T16:44:55.535784Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"}],"execution_count":5},{"id":"410ed982","cell_type":"code","source":"pos_vectorizer = CountVectorizer()\nX_train_pos_bow = pos_vectorizer.fit_transform(df_train[\"pos_text\"])\nX_test_pos_bow = pos_vectorizer.transform(df_test[\"pos_text\"])\n\npos_tfidf_transformer = TfidfTransformer()\nX_train_pos_tfidf = pos_tfidf_transformer.fit_transform(X_train_pos_bow)\nX_test_pos_tfidf = pos_tfidf_transformer.transform(X_test_pos_bow)\n\nX_train_combined = hstack([X_train_tfidf_lemmatized, X_train_pos_tfidf])\nX_test_combined = hstack([X_test_tfidf_lemmatized, X_test_pos_tfidf])","metadata":{"id":"410ed982","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:46:51.901908Z","iopub.execute_input":"2025-03-20T16:46:51.902378Z","iopub.status.idle":"2025-03-20T16:46:52.363884Z","shell.execute_reply.started":"2025-03-20T16:46:51.902341Z","shell.execute_reply":"2025-03-20T16:46:52.362943Z"}},"outputs":[],"execution_count":6},{"id":"0bad69d0-2f10-40b3-bffe-ad135aaa8381","cell_type":"code","source":"y_train = df_train[\"label\"]\ny_test = df_test[\"label\"]\n\nsvc_model = LinearSVC(random_state=42, C=0.1)\nsvc_model.fit(X_train_combined, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:53:22.005600Z","iopub.execute_input":"2025-03-20T16:53:22.005977Z","iopub.status.idle":"2025-03-20T16:53:22.067292Z","shell.execute_reply.started":"2025-03-20T16:53:22.005949Z","shell.execute_reply":"2025-03-20T16:53:22.066380Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"LinearSVC(C=0.1, random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=0.1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.1, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":8},{"id":"3e5b908f","cell_type":"code","source":"y_pred_svc = svc_model.predict(X_test_combined)\nprint(\"Accuracy (TF-IDF + POS + Embeddings + LinearSVC):\", accuracy_score(y_test, y_pred_svc))\nprint(classification_report(y_test, y_pred_svc))","metadata":{"id":"3e5b908f","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:53:25.936578Z","iopub.execute_input":"2025-03-20T16:53:25.936937Z","iopub.status.idle":"2025-03-20T16:53:25.952069Z","shell.execute_reply.started":"2025-03-20T16:53:25.936908Z","shell.execute_reply":"2025-03-20T16:53:25.951195Z"}},"outputs":[{"name":"stdout","text":"Accuracy (TF-IDF + POS + Embeddings + LinearSVC): 0.835383962664404\n              precision    recall  f1-score   support\n\n           0       0.86      0.82      0.84      1213\n           1       0.81      0.86      0.83      1144\n\n    accuracy                           0.84      2357\n   macro avg       0.84      0.84      0.84      2357\nweighted avg       0.84      0.84      0.84      2357\n\n","output_type":"stream"}],"execution_count":9},{"id":"378c0cd7","cell_type":"markdown","source":"## Task 3: Development of new features to improve classification accuracy\n\nCome up with another feature or set of features and help Alice improve the quality. Remember that Alice is in the past and does not have access to any . Additional training data cannot be used either. You can use third-party resources to generate features.\n\nCompare with result of your **baseline** from the Task 1. Any improvement will be counted. Use X_train_tfidf_lemmatized and X_test_tfidf_lemmatized, add combine your features with them as in task 2.","metadata":{"id":"378c0cd7"}},{"id":"9bf3136d-1e8b-4d34-b81a-2cd749697e9e","cell_type":"code","source":"pip install textblob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:54:46.615500Z","iopub.execute_input":"2025-03-20T16:54:46.615886Z","iopub.status.idle":"2025-03-20T16:54:49.894747Z","shell.execute_reply.started":"2025-03-20T16:54:46.615857Z","shell.execute_reply":"2025-03-20T16:54:49.893567Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\nRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"id":"vSXv61eH4G9e","cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.sparse import hstack\nfrom textblob import TextBlob\nfrom sklearn.preprocessing import StandardScaler\n\ndf_train = pd.read_csv(\"imdb_train_hw1.csv\")\ndf_test = pd.read_csv(\"imdb_test_hw1.csv\")\n\ndef get_custom_feature(text):\n    blob = TextBlob(text)\n    return [blob.sentiment.polarity, blob.sentiment.subjectivity]","metadata":{"id":"vSXv61eH4G9e","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:54:54.475894Z","iopub.execute_input":"2025-03-20T16:54:54.476240Z","iopub.status.idle":"2025-03-20T16:54:54.778942Z","shell.execute_reply.started":"2025-03-20T16:54:54.476211Z","shell.execute_reply":"2025-03-20T16:54:54.777973Z"}},"outputs":[],"execution_count":11},{"id":"2cc902b8","cell_type":"code","source":"df_train[\"sentiment_score\"] = df_train[\"text\"].apply(lambda x: get_custom_feature(x)[0])\ndf_train[\"subjectivity_score\"] = df_train[\"text\"].apply(lambda x: get_custom_feature(x)[1])\ndf_test[\"sentiment_score\"] = df_test[\"text\"].apply(lambda x: get_custom_feature(x)[0])\ndf_test[\"subjectivity_score\"] = df_test[\"text\"].apply(lambda x: get_custom_feature(x)[1])\n\nscaler = StandardScaler()\nX_train_sentiment = scaler.fit_transform(df_train[[\"sentiment_score\", \"subjectivity_score\"]])\nX_test_sentiment = scaler.transform(df_test[[\"sentiment_score\", \"subjectivity_score\"]])","metadata":{"id":"2cc902b8","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:55:14.109174Z","iopub.execute_input":"2025-03-20T16:55:14.109536Z","iopub.status.idle":"2025-03-20T16:55:34.284198Z","shell.execute_reply.started":"2025-03-20T16:55:14.109503Z","shell.execute_reply":"2025-03-20T16:55:34.283497Z"}},"outputs":[],"execution_count":12},{"id":"6ca5a10c-7d8d-443b-a886-03eb783229c0","cell_type":"code","source":"X_train_combined = hstack([X_train_tfidf_lemmatized, X_train_sentiment])\nX_test_combined = hstack([X_test_tfidf_lemmatized, X_test_sentiment])\n\nsvc_model = LinearSVC(random_state=42, C=0.1)\nsvc_model.fit(X_train_combined, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:55:36.841671Z","iopub.execute_input":"2025-03-20T16:55:36.842040Z","iopub.status.idle":"2025-03-20T16:55:37.050806Z","shell.execute_reply.started":"2025-03-20T16:55:36.842011Z","shell.execute_reply":"2025-03-20T16:55:37.049814Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"LinearSVC(C=0.1, random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=0.1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.1, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":13},{"id":"c22869e3-64bf-47ae-8478-33326645bc5c","cell_type":"code","source":"y_pred_svc = svc_model.predict(X_test_combined)\nprint(\"Accuracy (TF-IDF + Sentiment + LinearSVC):\", accuracy_score(y_test, y_pred_svc))\nprint(classification_report(y_test, y_pred_svc))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:55:39.048026Z","iopub.execute_input":"2025-03-20T16:55:39.048322Z","iopub.status.idle":"2025-03-20T16:55:39.070764Z","shell.execute_reply.started":"2025-03-20T16:55:39.048299Z","shell.execute_reply":"2025-03-20T16:55:39.069767Z"}},"outputs":[{"name":"stdout","text":"Accuracy (TF-IDF + Sentiment + LinearSVC): 0.8294442087399236\n              precision    recall  f1-score   support\n\n           0       0.84      0.82      0.83      1213\n           1       0.81      0.84      0.83      1144\n\n    accuracy                           0.83      2357\n   macro avg       0.83      0.83      0.83      2357\nweighted avg       0.83      0.83      0.83      2357\n\n","output_type":"stream"}],"execution_count":14}]}